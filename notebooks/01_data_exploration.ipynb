{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42706115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration and Analysis\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Custom modules\n",
    "from src.data.dataset import COCOVisionDataset\n",
    "from src.data.transforms import VisionTransforms\n",
    "from src.data.streaming import CameraStreamSimulator\n",
    "from src.utils.logging import setup_logger\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import display, HTML\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'data_root': '../data/coco',\n",
    "    'image_size': (416, 416),\n",
    "    'batch_size': 16,\n",
    "    'num_workers': 4,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(config['seed'])\n",
    "np.random.seed(config['seed'])\n",
    "random.seed(config['seed'])\n",
    "\n",
    "# Initialize logger\n",
    "logger = setup_logger('data_exploration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cfe71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dataset Statistics Analysis\n",
    "class DatasetAnalyzer:\n",
    "    \"\"\"Analyze dataset statistics and quality.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_root):\n",
    "        self.data_root = Path(data_root)\n",
    "        self.annotations_path = self.data_root / 'annotations'\n",
    "        \n",
    "    def load_coco_stats(self):\n",
    "        \"\"\"Load COCO dataset statistics.\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        # Load annotation files\n",
    "        annotation_files = {\n",
    "            'train': 'instances_train2017.json',\n",
    "            'val': 'instances_val2017.json',\n",
    "            'test': 'image_info_test2017.json'\n",
    "        }\n",
    "        \n",
    "        for split, filename in annotation_files.items():\n",
    "            filepath = self.annotations_path / filename\n",
    "            if filepath.exists():\n",
    "                with open(filepath, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    \n",
    "                stats[split] = {\n",
    "                    'num_images': len(data['images']),\n",
    "                    'num_annotations': len(data['annotations']),\n",
    "                    'categories': data['categories'],\n",
    "                    'images_per_category': defaultdict(int),\n",
    "                    'bbox_stats': self._analyze_bboxes(data['annotations']),\n",
    "                    'image_sizes': self._analyze_image_sizes(data['images'])\n",
    "                }\n",
    "                \n",
    "                # Count instances per category\n",
    "                for ann in data['annotations']:\n",
    "                    stats[split]['images_per_category'][ann['category_id']] += 1\n",
    "                    \n",
    "        return stats\n",
    "    \n",
    "    def _analyze_bboxes(self, annotations):\n",
    "        \"\"\"Analyze bounding box statistics.\"\"\"\n",
    "        bboxes = np.array([ann['bbox'] for ann in annotations])\n",
    "        \n",
    "        if len(bboxes) == 0:\n",
    "            return {}\n",
    "            \n",
    "        widths = bboxes[:, 2]\n",
    "        heights = bboxes[:, 3]\n",
    "        areas = widths * heights\n",
    "        aspect_ratios = widths / (heights + 1e-8)\n",
    "        \n",
    "        return {\n",
    "            'mean_width': float(widths.mean()),\n",
    "            'mean_height': float(heights.mean()),\n",
    "            'mean_area': float(areas.mean()),\n",
    "            'mean_aspect_ratio': float(aspect_ratios.mean()),\n",
    "            'std_width': float(widths.std()),\n",
    "            'std_height': float(heights.std()),\n",
    "            'min_width': float(widths.min()),\n",
    "            'max_width': float(widths.max()),\n",
    "            'min_height': float(heights.min()),\n",
    "            'max_height': float(heights.max())\n",
    "        }\n",
    "    \n",
    "    def _analyze_image_sizes(self, images):\n",
    "        \"\"\"Analyze image size statistics.\"\"\"\n",
    "        widths = np.array([img['width'] for img in images])\n",
    "        heights = np.array([img['height'] for img in images])\n",
    "        aspect_ratios = widths / heights\n",
    "        \n",
    "        return {\n",
    "            'mean_width': float(widths.mean()),\n",
    "            'mean_height': float(heights.mean()),\n",
    "            'mean_aspect_ratio': float(aspect_ratios.mean()),\n",
    "            'std_width': float(widths.std()),\n",
    "            'std_height': float(heights.std()),\n",
    "            'resolutions': [(w, h) for w, h in zip(widths, heights)]\n",
    "        }\n",
    "    \n",
    "    def visualize_stats(self, stats):\n",
    "        \"\"\"Visualize dataset statistics.\"\"\"\n",
    "        fig = make_subplots(\n",
    "            rows=3, cols=3,\n",
    "            subplot_titles=(\n",
    "                'Images per Split', 'Annotations per Split',\n",
    "                'Category Distribution', 'BBox Width Distribution',\n",
    "                'BBox Height Distribution', 'BBox Aspect Ratios',\n",
    "                'Image Width Distribution', 'Image Height Distribution',\n",
    "                'Object Density Heatmap'\n",
    "            ),\n",
    "            specs=[[{'type': 'bar'}, {'type': 'bar'}, {'type': 'bar'}],\n",
    "                   [{'type': 'histogram'}, {'type': 'histogram'}, {'type': 'histogram'}],\n",
    "                   [{'type': 'histogram'}, {'type': 'histogram'}, {'type': 'heatmap'}]]\n",
    "        )\n",
    "        \n",
    "        # 1. Images per split\n",
    "        splits = list(stats.keys())\n",
    "        image_counts = [stats[split]['num_images'] for split in splits]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=splits, y=image_counts, name='Images'),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # 2. Annotations per split\n",
    "        annotation_counts = [stats[split]['num_annotations'] for split in splits]\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=splits, y=annotation_counts, name='Annotations'),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # 3. Category distribution (train split)\n",
    "        if 'train' in stats:\n",
    "            categories = stats['train']['categories']\n",
    "            cat_names = [cat['name'] for cat in categories]\n",
    "            cat_ids = [cat['id'] for cat in categories]\n",
    "            cat_counts = [stats['train']['images_per_category'][cid] for cid in cat_ids]\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Bar(x=cat_names[:20], y=cat_counts[:20], name='Categories'),\n",
    "                row=1, col=3\n",
    "            )\n",
    "        \n",
    "        # 4-6. BBox distributions\n",
    "        if 'train' in stats and 'bbox_stats' in stats['train']:\n",
    "            bbox_stats = stats['train']['bbox_stats']\n",
    "            \n",
    "            # Simulate bbox data for visualization\n",
    "            np.random.seed(42)\n",
    "            widths = np.random.normal(bbox_stats['mean_width'], bbox_stats['std_width'], 1000)\n",
    "            heights = np.random.normal(bbox_stats['mean_height'], bbox_stats['std_height'], 1000)\n",
    "            aspect_ratios = widths / heights\n",
    "            \n",
    "            fig.add_trace(go.Histogram(x=widths, nbinsx=50), row=2, col=1)\n",
    "            fig.add_trace(go.Histogram(x=heights, nbinsx=50), row=2, col=2)\n",
    "            fig.add_trace(go.Histogram(x=aspect_ratios, nbinsx=50), row=2, col=3)\n",
    "        \n",
    "        # 7-8. Image size distributions\n",
    "        if 'train' in stats and 'image_sizes' in stats['train']:\n",
    "            img_stats = stats['train']['image_sizes']\n",
    "            \n",
    "            # Simulate image size data\n",
    "            widths = np.random.normal(img_stats['mean_width'], img_stats['std_width'], 1000)\n",
    "            heights = np.random.normal(img_stats['mean_height'], img_stats['std_height'], 1000)\n",
    "            \n",
    "            fig.add_trace(go.Histogram(x=widths, nbinsx=50), row=3, col=1)\n",
    "            fig.add_trace(go.Histogram(x=heights, nbinsx=50), row=3, col=2)\n",
    "        \n",
    "        # 9. Object density heatmap (simulated)\n",
    "        heatmap_data = np.random.rand(20, 20)\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=heatmap_data, colorscale='Viridis'),\n",
    "            row=3, col=3\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=1000, showlegend=False, title_text=\"Dataset Statistics\")\n",
    "        fig.show()\n",
    "\n",
    "# %%\n",
    "# Initialize analyzer\n",
    "analyzer = DatasetAnalyzer(config['data_root'])\n",
    "\n",
    "# Load statistics\n",
    "try:\n",
    "    stats = analyzer.load_coco_stats()\n",
    "    print(\"Dataset Statistics Loaded Successfully!\")\n",
    "    print(\"\\nSummary:\")\n",
    "    for split, data in stats.items():\n",
    "        print(f\"\\n{split.upper()}:\")\n",
    "        print(f\"  Images: {data['num_images']:,}\")\n",
    "        print(f\"  Annotations: {data['num_annotations']:,}\")\n",
    "        if 'bbox_stats' in data:\n",
    "            print(f\"  Mean BBox Area: {data['bbox_stats']['mean_area']:.1f}\")\n",
    "            \n",
    "    # Visualize\n",
    "    analyzer.visualize_stats(stats)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading COCO stats: {e}\")\n",
    "    print(\"\\nUsing simulated statistics for demonstration...\")\n",
    "    \n",
    "    # Create simulated statistics\n",
    "    stats = {\n",
    "        'train': {\n",
    "            'num_images': 118287,\n",
    "            'num_annotations': 860001,\n",
    "            'categories': [{'id': i, 'name': f'class_{i}'} for i in range(1, 81)],\n",
    "            'images_per_category': {i: np.random.randint(100, 10000) for i in range(1, 81)},\n",
    "            'bbox_stats': {\n",
    "                'mean_width': 45.6, 'mean_height': 67.8, 'mean_area': 3085.7,\n",
    "                'mean_aspect_ratio': 0.72, 'std_width': 12.3, 'std_height': 18.9,\n",
    "                'min_width': 5.0, 'max_width': 300.0, 'min_height': 5.0, 'max_height': 300.0\n",
    "            },\n",
    "            'image_sizes': {\n",
    "                'mean_width': 640, 'mean_height': 480, 'mean_aspect_ratio': 1.33,\n",
    "                'std_width': 120, 'std_height': 90,\n",
    "                'resolutions': [(640, 480)] * 1000\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    analyzer.visualize_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e38f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Loading Pipeline Test\n",
    "class DataPipelineTester:\n",
    "    \"\"\"Test the complete data loading pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.transforms = VisionTransforms(\n",
    "            image_size=config['image_size'],\n",
    "            training=True\n",
    "        )\n",
    "        \n",
    "    def test_coco_dataset(self):\n",
    "        \"\"\"Test COCO dataset loading.\"\"\"\n",
    "        print(\"Testing COCO Dataset Loading...\")\n",
    "        \n",
    "        try:\n",
    "            # Create dataset\n",
    "            dataset = COCOVisionDataset(\n",
    "                root_dir=self.config['data_root'],\n",
    "                split='train',\n",
    "                transform=self.transforms.get_training_transforms(),\n",
    "                max_samples=100  # Limit for testing\n",
    "            )\n",
    "            \n",
    "            print(f\"Dataset created successfully!\")\n",
    "            print(f\"Number of samples: {len(dataset)}\")\n",
    "            \n",
    "            # Test sample\n",
    "            sample = dataset[0]\n",
    "            print(f\"\\nSample structure:\")\n",
    "            for key, value in sample.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    print(f\"  {key}: {value.shape}, dtype={value.dtype}\")\n",
    "                else:\n",
    "                    print(f\"  {key}: {type(value)}\")\n",
    "            \n",
    "            # Show a few samples\n",
    "            self.visualize_samples(dataset, num_samples=5)\n",
    "            \n",
    "            return dataset\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating dataset: {e}\")\n",
    "            print(\"\\nCreating simulated dataset...\")\n",
    "            return self.create_simulated_dataset()\n",
    "    \n",
    "    def create_simulated_dataset(self):\n",
    "        \"\"\"Create simulated dataset for testing.\"\"\"\n",
    "        class SimulatedDataset(Dataset):\n",
    "            def __init__(self, num_samples=100, image_size=(416, 416)):\n",
    "                self.num_samples = num_samples\n",
    "                self.image_size = image_size\n",
    "                \n",
    "            def __len__(self):\n",
    "                return self.num_samples\n",
    "                \n",
    "            def __getitem__(self, idx):\n",
    "                # Simulate image\n",
    "                image = torch.randn(3, *self.image_size)\n",
    "                \n",
    "                # Simulate bboxes (normalized coordinates)\n",
    "                num_objects = random.randint(1, 5)\n",
    "                bboxes = torch.rand(num_objects, 4)  # x, y, w, h\n",
    "                bboxes[:, 2:] = bboxes[:, 2:] * 0.3 + 0.1  # Reasonable sizes\n",
    "                \n",
    "                # Simulate labels\n",
    "                labels = torch.randint(0, 80, (num_objects,))\n",
    "                \n",
    "                return {\n",
    "                    'image': image,\n",
    "                    'bboxes': bboxes,\n",
    "                    'labels': labels,\n",
    "                    'image_id': idx\n",
    "                }\n",
    "        \n",
    "        return SimulatedDataset()\n",
    "    \n",
    "    def visualize_samples(self, dataset, num_samples=3):\n",
    "        \"\"\"Visualize dataset samples.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(min(num_samples, len(axes))):\n",
    "            sample = dataset[i]\n",
    "            image = sample['image']\n",
    "            \n",
    "            # Denormalize if needed\n",
    "            if image.min() < 0:  # Assuming normalized\n",
    "                image = (image - image.min()) / (image.max() - image.min())\n",
    "            \n",
    "            # Convert to numpy for display\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                image = image.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            axes[i].imshow(image)\n",
    "            \n",
    "            # Draw bboxes if available\n",
    "            if 'bboxes' in sample:\n",
    "                bboxes = sample['bboxes']\n",
    "                if isinstance(bboxes, torch.Tensor):\n",
    "                    bboxes = bboxes.numpy()\n",
    "                \n",
    "                for bbox in bboxes:\n",
    "                    if len(bbox) >= 4:  # x, y, w, h format\n",
    "                        x, y, w, h = bbox\n",
    "                        rect = plt.Rectangle(\n",
    "                            (x * image.shape[1], y * image.shape[0]),\n",
    "                            w * image.shape[1], h * image.shape[0],\n",
    "                            linewidth=2, edgecolor='r', facecolor='none'\n",
    "                        )\n",
    "                        axes[i].add_patch(rect)\n",
    "            \n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f'Sample {i}')\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for i in range(num_samples, len(axes)):\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def test_dataloader(self, dataset):\n",
    "        \"\"\"Test dataloader performance.\"\"\"\n",
    "        print(\"\\nTesting DataLoader Performance...\")\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=self.config['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=self.config['num_workers'],\n",
    "            pin_memory=True,\n",
    "            collate_fn=self.collate_fn\n",
    "        )\n",
    "        \n",
    "        # Test batch loading\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if batch_idx >= 3:  # Test first 3 batches\n",
    "                break\n",
    "                \n",
    "            print(f\"\\nBatch {batch_idx}:\")\n",
    "            for key, value in batch.items():\n",
    "                if isinstance(value, torch.Tensor):\n",
    "                    print(f\"  {key}: {value.shape}\")\n",
    "            \n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"\\nTime for 3 batches: {elapsed:.2f} seconds\")\n",
    "        \n",
    "        return dataloader\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Custom collate function for variable-sized bboxes.\"\"\"\n",
    "        images = []\n",
    "        bboxes = []\n",
    "        labels = []\n",
    "        image_ids = []\n",
    "        \n",
    "        for item in batch:\n",
    "            images.append(item['image'])\n",
    "            bboxes.append(item['bboxes'])\n",
    "            labels.append(item['labels'])\n",
    "            image_ids.append(item['image_id'])\n",
    "        \n",
    "        # Stack images\n",
    "        images = torch.stack(images, dim=0)\n",
    "        \n",
    "        return {\n",
    "            'images': images,\n",
    "            'bboxes': bboxes,\n",
    "            'labels': labels,\n",
    "            'image_ids': image_ids\n",
    "        }\n",
    "\n",
    "# Test data pipeline\n",
    "tester = DataPipelineTester(config)\n",
    "dataset = tester.test_coco_dataset()\n",
    "dataloader = tester.test_dataloader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd118b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Augmentation Pipeline Analysis\n",
    "\n",
    "class AugmentationAnalyzer:\n",
    "    \"\"\"Analyze augmentation effects.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=(416, 416)):\n",
    "        self.image_size = image_size\n",
    "        self.transforms = VisionTransforms(image_size=image_size)\n",
    "        \n",
    "    def visualize_augmentations(self, image_path=None, num_augs=9):\n",
    "        \"\"\"Visualize different augmentations on same image.\"\"\"\n",
    "        \n",
    "        if image_path is None or not os.path.exists(image_path):\n",
    "            # Create synthetic image\n",
    "            print(\"Creating synthetic image for augmentation visualization...\")\n",
    "            image = np.random.randint(0, 255, (416, 416, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, self.image_size)\n",
    "        \n",
    "        # Get augmentation pipeline\n",
    "        augmentations = self.transforms.get_training_transforms()\n",
    "        \n",
    "        # Apply different augmentations\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title('Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        for i in range(1, num_augs):\n",
    "            # Apply augmentation\n",
    "            augmented = augmentations(image=image)['image']\n",
    "            \n",
    "            if isinstance(augmented, torch.Tensor):\n",
    "                augmented = augmented.permute(1, 2, 0).numpy()\n",
    "                # Denormalize if needed\n",
    "                if augmented.min() < 0:\n",
    "                    augmented = (augmented - augmented.min()) / (augmented.max() - augmented.min())\n",
    "            \n",
    "            axes[i].imshow(augmented)\n",
    "            axes[i].set_title(f'Augmentation {i}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def analyze_augmentation_stats(self, dataset, num_samples=100):\n",
    "        \"\"\"Analyze statistics before/after augmentation.\"\"\"\n",
    "        print(\"\\nAnalyzing Augmentation Statistics...\")\n",
    "        \n",
    "        original_stats = {\n",
    "            'mean': [], 'std': [], 'min': [], 'max': []\n",
    "        }\n",
    "        augmented_stats = {\n",
    "            'mean': [], 'std': [], 'min': [], 'max': []\n",
    "        }\n",
    "        \n",
    "        transforms_pipeline = self.transforms.get_training_transforms()\n",
    "        \n",
    "        for i in range(min(num_samples, len(dataset))):\n",
    "            sample = dataset[i]\n",
    "            image = sample['image']\n",
    "            \n",
    "            # Original stats\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                original_stats['mean'].append(image.mean().item())\n",
    "                original_stats['std'].append(image.std().item())\n",
    "                original_stats['min'].append(image.min().item())\n",
    "                original_stats['max'].append(image.max().item())\n",
    "            \n",
    "            # Apply augmentation\n",
    "            if isinstance(image, torch.Tensor):\n",
    "                image_np = image.permute(1, 2, 0).numpy()\n",
    "            else:\n",
    "                image_np = image\n",
    "            \n",
    "            augmented = transforms_pipeline(image=image_np)['image']\n",
    "            \n",
    "            if isinstance(augmented, torch.Tensor):\n",
    "                augmented_stats['mean'].append(augmented.mean().item())\n",
    "                augmented_stats['std'].append(augmented.std().item())\n",
    "                augmented_stats['min'].append(augmented.min().item())\n",
    "                augmented_stats['max'].append(augmented.max().item())\n",
    "        \n",
    "        # Create comparison plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        metrics = ['mean', 'std', 'min', 'max']\n",
    "        titles = ['Mean', 'Standard Deviation', 'Minimum', 'Maximum']\n",
    "        \n",
    "        for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "            ax = axes[idx // 2, idx % 2]\n",
    "            \n",
    "            ax.hist(original_stats[metric], alpha=0.5, label='Original', bins=30)\n",
    "            ax.hist(augmented_stats[metric], alpha=0.5, label='Augmented', bins=30)\n",
    "            \n",
    "            ax.set_xlabel('Pixel Value')\n",
    "            ax.set_ylabel('Frequency')\n",
    "            ax.set_title(f'{title} Distribution')\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"{'Metric':<20} {'Original':<15} {'Augmented':<15}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            orig_mean = np.mean(original_stats[metric])\n",
    "            aug_mean = np.mean(augmented_stats[metric])\n",
    "            print(f\"{metric:<20} {orig_mean:<15.4f} {aug_mean:<15.4f}\")\n",
    "\n",
    "# Analyze augmentations\n",
    "aug_analyzer = AugmentationAnalyzer(image_size=config['image_size'])\n",
    "\n",
    "# Visualize augmentations\n",
    "aug_analyzer.visualize_augmentations()\n",
    "\n",
    "# Analyze augmentation statistics\n",
    "aug_analyzer.analyze_augmentation_stats(dataset, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6047a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Streaming Data Simulation\n",
    "class StreamingAnalyzer:\n",
    "    \"\"\"Analyze streaming data pipeline for robotic vision.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.stream_simulator = CameraStreamSimulator(\n",
    "            fps=30,\n",
    "            resolution=config['image_size'],\n",
    "            buffer_size=10\n",
    "        )\n",
    "        \n",
    "    def simulate_streaming(self, duration_sec=5):\n",
    "        \"\"\"Simulate real-time camera streaming.\"\"\"\n",
    "        print(f\"\\nSimulating Camera Streaming for {duration_sec} seconds...\")\n",
    "        print(f\"FPS: 30, Resolution: {self.config['image_size']}\")\n",
    "        \n",
    "        frames = []\n",
    "        timestamps = []\n",
    "        \n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while time.time() - start_time < duration_sec:\n",
    "            # Get frame from simulator\n",
    "            frame, timestamp = self.stream_simulator.get_frame()\n",
    "            frames.append(frame)\n",
    "            timestamps.append(timestamp)\n",
    "            \n",
    "            # Simulate processing delay\n",
    "            time.sleep(1/30)  # 30 FPS\n",
    "        \n",
    "        print(f\"Captured {len(frames)} frames\")\n",
    "        print(f\"Average FPS: {len(frames)/duration_sec:.1f}\")\n",
    "        \n",
    "        # Analyze frame statistics\n",
    "        self.analyze_stream_stats(frames, timestamps)\n",
    "        \n",
    "        # Visualize stream\n",
    "        self.visualize_stream(frames)\n",
    "        \n",
    "        return frames, timestamps\n",
    "    \n",
    "    def analyze_stream_stats(self, frames, timestamps):\n",
    "        \"\"\"Analyze streaming statistics.\"\"\"\n",
    "        if not frames:\n",
    "            return\n",
    "            \n",
    "        # Calculate frame intervals\n",
    "        intervals = np.diff(timestamps)\n",
    "        \n",
    "        # Calculate frame statistics\n",
    "        frame_shapes = [frame.shape for frame in frames]\n",
    "        heights = [shape[0] for shape in frame_shapes]\n",
    "        widths = [shape[1] for shape in frame_shapes]\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Frame intervals\n",
    "        axes[0, 0].plot(intervals, marker='o', linestyle='-', alpha=0.6)\n",
    "        axes[0, 0].axhline(y=1/30, color='r', linestyle='--', label='Target (33.3ms)')\n",
    "        axes[0, 0].set_xlabel('Frame Index')\n",
    "        axes[0, 0].set_ylabel('Interval (seconds)')\n",
    "        axes[0, 0].set_title('Frame Intervals')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Frame size distribution\n",
    "        axes[0, 1].hist(widths, bins=20, alpha=0.7, label='Width')\n",
    "        axes[0, 1].hist(heights, bins=20, alpha=0.7, label='Height')\n",
    "        axes[0, 1].set_xlabel('Pixels')\n",
    "        axes[0, 1].set_ylabel('Frequency')\n",
    "        axes[0, 1].set_title('Frame Size Distribution')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Frame mean intensity\n",
    "        mean_intensities = [frame.mean() for frame in frames]\n",
    "        axes[1, 0].plot(mean_intensities, marker='o', linestyle='-', alpha=0.6)\n",
    "        axes[1, 0].set_xlabel('Frame Index')\n",
    "        axes[1, 0].set_ylabel('Mean Intensity')\n",
    "        axes[1, 0].set_title('Frame Brightness Over Time')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Histogram of frame values\n",
    "        all_pixels = np.concatenate([frame.flatten() for frame in frames])\n",
    "        axes[1, 1].hist(all_pixels, bins=50, alpha=0.7)\n",
    "        axes[1, 1].set_xlabel('Pixel Value')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Pixel Value Distribution')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nStreaming Statistics:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Total frames: {len(frames)}\")\n",
    "        print(f\"Average interval: {np.mean(intervals)*1000:.1f} ms\")\n",
    "        print(f\"Interval std: {np.std(intervals)*1000:.1f} ms\")\n",
    "        print(f\"Frame size: {frames[0].shape}\")\n",
    "        print(f\"Average brightness: {np.mean(mean_intensities):.1f}\")\n",
    "    \n",
    "    def visualize_stream(self, frames, num_frames=9):\n",
    "        \"\"\"Visualize sample frames from stream.\"\"\"\n",
    "        if len(frames) < num_frames:\n",
    "            num_frames = len(frames)\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        indices = np.linspace(0, len(frames)-1, num_frames, dtype=int)\n",
    "        \n",
    "        for idx, ax_idx in enumerate(indices):\n",
    "            frame = frames[ax_idx]\n",
    "            axes[idx].imshow(frame)\n",
    "            axes[idx].set_title(f'Frame {ax_idx}')\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Test streaming pipeline\n",
    "stream_analyzer = StreamingAnalyzer(config)\n",
    "frames, timestamps = stream_analyzer.simulate_streaming(duration_sec=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Checks\n",
    "class DataQualityChecker:\n",
    "    \"\"\"Perform data quality checks.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def check_image_quality(self, num_samples=100):\n",
    "        \"\"\"Check image quality metrics.\"\"\"\n",
    "        print(\"\\nPerforming Image Quality Checks...\")\n",
    "        \n",
    "        quality_metrics = {\n",
    "            'contrast': [],\n",
    "            'brightness': [],\n",
    "            'sharpness': [],\n",
    "            'entropy': [],\n",
    "            'saturation': []\n",
    "        }\n",
    "        \n",
    "        for i in range(min(num_samples, len(self.dataset))):\n",
    "            sample = self.dataset[i]\n",
    "            image = sample['image']\n",
    "            \n",
    "            if isinstance(image, torch.Tensor):\n",
    "                image_np = image.permute(1, 2, 0).numpy()\n",
    "                if image_np.min() < 0:  # Normalized\n",
    "                    image_np = (image_np - image_np.min()) / (image_np.max() - image_np.min())\n",
    "                image_np = (image_np * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image_np = image\n",
    "            \n",
    "            if len(image_np.shape) == 3 and image_np.shape[2] == 3:\n",
    "                # Convert to grayscale for some metrics\n",
    "                gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                quality_metrics['contrast'].append(gray.std())\n",
    "                quality_metrics['brightness'].append(gray.mean())\n",
    "                quality_metrics['sharpness'].append(self._calculate_sharpness(gray))\n",
    "                quality_metrics['entropy'].append(self._calculate_entropy(gray))\n",
    "                \n",
    "                # Calculate saturation\n",
    "                hsv = cv2.cvtColor(image_np, cv2.COLOR_RGB2HSV)\n",
    "                quality_metrics['saturation'].append(hsv[:, :, 1].mean())\n",
    "        \n",
    "        # Create quality report\n",
    "        self.create_quality_report(quality_metrics)\n",
    "        \n",
    "        # Visualize quality metrics\n",
    "        self.visualize_quality_metrics(quality_metrics)\n",
    "        \n",
    "        return quality_metrics\n",
    "    \n",
    "    def _calculate_sharpness(self, image):\n",
    "        \"\"\"Calculate image sharpness using Laplacian variance.\"\"\"\n",
    "        return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    \n",
    "    def _calculate_entropy(self, image):\n",
    "        \"\"\"Calculate image entropy.\"\"\"\n",
    "        hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "        hist = hist / hist.sum()\n",
    "        entropy = -np.sum(hist * np.log2(hist + 1e-10))\n",
    "        return entropy\n",
    "    \n",
    "    def create_quality_report(self, quality_metrics):\n",
    "        \"\"\"Create data quality report.\"\"\"\n",
    "        print(\"\\nData Quality Report:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for metric_name, values in quality_metrics.items():\n",
    "            if values:\n",
    "                mean_val = np.mean(values)\n",
    "                std_val = np.std(values)\n",
    "                min_val = np.min(values)\n",
    "                max_val = np.max(values)\n",
    "                \n",
    "                print(f\"\\n{metric_name.upper()}:\")\n",
    "                print(f\"  Mean: {mean_val:.2f}\")\n",
    "                print(f\"  Std: {std_val:.2f}\")\n",
    "                print(f\"  Range: [{min_val:.2f}, {max_val:.2f}]\")\n",
    "                \n",
    "                # Quality assessment\n",
    "                if metric_name == 'contrast':\n",
    "                    if mean_val < 30:\n",
    "                        assessment = \"LOW - Consider contrast enhancement\"\n",
    "                    elif mean_val > 100:\n",
    "                        assessment = \"HIGH - Good contrast\"\n",
    "                    else:\n",
    "                        assessment = \"MEDIUM - Acceptable\"\n",
    "                elif metric_name == 'brightness':\n",
    "                    if mean_val < 50:\n",
    "                        assessment = \"DARK - May need brightness adjustment\"\n",
    "                    elif mean_val > 200:\n",
    "                        assessment = \"BRIGHT - May need dimming\"\n",
    "                    else:\n",
    "                        assessment = \"GOOD - Well balanced\"\n",
    "                elif metric_name == 'sharpness':\n",
    "                    if mean_val < 100:\n",
    "                        assessment = \"BLURRY - Consider sharpening\"\n",
    "                    else:\n",
    "                        assessment = \"SHARP - Good quality\"\n",
    "                else:\n",
    "                    assessment = \"OK\"\n",
    "                \n",
    "                print(f\"  Assessment: {assessment}\")\n",
    "    \n",
    "    def visualize_quality_metrics(self, quality_metrics):\n",
    "        \"\"\"Visualize quality metrics.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        metrics_list = list(quality_metrics.keys())\n",
    "        \n",
    "        for idx, metric_name in enumerate(metrics_list):\n",
    "            if idx < len(axes):\n",
    "                values = quality_metrics[metric_name]\n",
    "                \n",
    "                if values:\n",
    "                    axes[idx].hist(values, bins=30, alpha=0.7, edgecolor='black')\n",
    "                    axes[idx].axvline(np.mean(values), color='red', linestyle='--', \n",
    "                                    label=f'Mean: {np.mean(values):.1f}')\n",
    "                    axes[idx].set_xlabel(metric_name.title())\n",
    "                    axes[idx].set_ylabel('Frequency')\n",
    "                    axes[idx].set_title(f'{metric_name.title()} Distribution')\n",
    "                    axes[idx].legend()\n",
    "                    axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(len(metrics_list), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def check_label_consistency(self, num_samples=100):\n",
    "        \"\"\"Check label consistency and distribution.\"\"\"\n",
    "        print(\"\\nChecking Label Consistency...\")\n",
    "        \n",
    "        all_labels = []\n",
    "        bbox_stats = {'widths': [], 'heights': [], 'areas': []}\n",
    "        \n",
    "        for i in range(min(num_samples, len(self.dataset))):\n",
    "            sample = self.dataset[i]\n",
    "            \n",
    "            if 'labels' in sample:\n",
    "                labels = sample['labels']\n",
    "                if isinstance(labels, torch.Tensor):\n",
    "                    all_labels.extend(labels.numpy().tolist())\n",
    "            \n",
    "            if 'bboxes' in sample:\n",
    "                bboxes = sample['bboxes']\n",
    "                if isinstance(bboxes, torch.Tensor):\n",
    "                    bboxes_np = bboxes.numpy()\n",
    "                    if len(bboxes_np) > 0:\n",
    "                        widths = bboxes_np[:, 2]\n",
    "                        heights = bboxes_np[:, 3]\n",
    "                        areas = widths * heights\n",
    "                        \n",
    "                        bbox_stats['widths'].extend(widths.tolist())\n",
    "                        bbox_stats['heights'].extend(heights.tolist())\n",
    "                        bbox_stats['areas'].extend(areas.tolist())\n",
    "        \n",
    "        # Analyze label distribution\n",
    "        if all_labels:\n",
    "            label_counts = Counter(all_labels)\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            # Label distribution\n",
    "            labels, counts = zip(*label_counts.most_common(20))\n",
    "            axes[0].bar(range(len(labels)), counts)\n",
    "            axes[0].set_xlabel('Label ID')\n",
    "            axes[0].set_ylabel('Count')\n",
    "            axes[0].set_title('Top 20 Label Distribution')\n",
    "            axes[0].set_xticks(range(len(labels)))\n",
    "            axes[0].set_xticklabels(labels, rotation=45)\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            print(f\"\\nTotal labels: {len(all_labels)}\")\n",
    "            print(f\"Unique labels: {len(label_counts)}\")\n",
    "            print(f\"Most common label: {label_counts.most_common(1)[0]}\")\n",
    "        \n",
    "        # Analyze bbox statistics\n",
    "        if bbox_stats['areas']:\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "            \n",
    "            metrics = ['widths', 'heights', 'areas']\n",
    "            titles = ['BBox Widths', 'BBox Heights', 'BBox Areas']\n",
    "            \n",
    "            for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "                values = bbox_stats[metric]\n",
    "                axes[idx].hist(values, bins=30, alpha=0.7, edgecolor='black')\n",
    "                axes[idx].axvline(np.mean(values), color='red', linestyle='--',\n",
    "                                label=f'Mean: {np.mean(values):.3f}')\n",
    "                axes[idx].set_xlabel(title)\n",
    "                axes[idx].set_ylabel('Frequency')\n",
    "                axes[idx].set_title(f'{title} Distribution')\n",
    "                axes[idx].legend()\n",
    "                axes[idx].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"\\nBBox Statistics:\")\n",
    "            print(f\"  Mean width: {np.mean(bbox_stats['widths']):.3f}\")\n",
    "            print(f\"  Mean height: {np.mean(bbox_stats['heights']):.3f}\")\n",
    "            print(f\"  Mean area: {np.mean(bbox_stats['areas']):.3f}\")\n",
    "\n",
    "\n",
    "# Run quality checks\n",
    "quality_checker = DataQualityChecker(dataset)\n",
    "quality_metrics = quality_checker.check_image_quality(num_samples=50)\n",
    "quality_checker.check_label_consistency(num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4dd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Usage Analysis\n",
    "class MemoryAnalyzer:\n",
    "    \"\"\"Analyze memory usage of data pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.memory_stats = []\n",
    "        \n",
    "    def analyze_batch_memory(self, dataloader, num_batches=5):\n",
    "        \"\"\"Analyze memory usage per batch.\"\"\"\n",
    "        print(\"\\nAnalyzing Batch Memory Usage...\")\n",
    "        \n",
    "        import psutil\n",
    "        import torch.cuda as cuda\n",
    "        \n",
    "        batch_sizes = []\n",
    "        memory_usages = []\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            if batch_idx >= num_batches:\n",
    "                break\n",
    "            \n",
    "            # Get batch size\n",
    "            images = batch['images']\n",
    "            batch_size = images.shape[0]\n",
    "            batch_sizes.append(batch_size)\n",
    "            \n",
    "            # Calculate memory usage\n",
    "            image_memory = images.element_size() * images.nelement()\n",
    "            \n",
    "            # Account for bboxes and labels\n",
    "            total_memory = image_memory\n",
    "            \n",
    "            for bbox_batch in batch['bboxes']:\n",
    "                if isinstance(bbox_batch, torch.Tensor):\n",
    "                    total_memory += bbox_batch.element_size() * bbox_batch.nelement()\n",
    "            \n",
    "            for label_batch in batch['labels']:\n",
    "                if isinstance(label_batch, torch.Tensor):\n",
    "                    total_memory += label_batch.element_size() * label_batch.nelement()\n",
    "            \n",
    "            memory_usages.append(total_memory / (1024**2))  # Convert to MB\n",
    "            \n",
    "            print(f\"Batch {batch_idx}: {batch_size} images, {total_memory/(1024**2):.2f} MB\")\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        axes[0].plot(batch_sizes, marker='o', linestyle='-')\n",
    "        axes[0].set_xlabel('Batch Index')\n",
    "        axes[0].set_ylabel('Batch Size')\n",
    "        axes[0].set_title('Batch Sizes')\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        axes[1].plot(memory_usages, marker='o', linestyle='-', color='orange')\n",
    "        axes[1].set_xlabel('Batch Index')\n",
    "        axes[1].set_ylabel('Memory (MB)')\n",
    "        axes[1].set_title('Memory Usage per Batch')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nAverage batch size: {np.mean(batch_sizes):.1f}\")\n",
    "        print(f\"Average memory per batch: {np.mean(memory_usages):.2f} MB\")\n",
    "        print(f\"Max memory per batch: {np.max(memory_usages):.2f} MB\")\n",
    "\n",
    "# Analyze memory usage\n",
    "memory_analyzer = MemoryAnalyzer()\n",
    "memory_analyzer.analyze_batch_memory(dataloader, num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Data Pipeline Recommendations\n",
    "\n",
    "class DataPipelineOptimizer:\n",
    "    \"\"\"Provide optimization recommendations for data pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, dataset_stats, quality_metrics):\n",
    "        self.config = config\n",
    "        self.dataset_stats = dataset_stats\n",
    "        self.quality_metrics = quality_metrics\n",
    "        \n",
    "    def generate_recommendations(self):\n",
    "        \"\"\"Generate data pipeline optimization recommendations.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATA PIPELINE OPTIMIZATION RECOMMENDATIONS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        recommendations = []\n",
    "        \n",
    "        # 1. Dataset imbalance\n",
    "        if 'train' in self.dataset_stats:\n",
    "            category_counts = list(self.dataset_stats['train']['images_per_category'].values())\n",
    "            imbalance_ratio = max(category_counts) / min(category_counts) if min(category_counts) > 0 else float('inf')\n",
    "            \n",
    "            if imbalance_ratio > 10:\n",
    "                recommendations.append({\n",
    "                    'issue': 'Severe class imbalance',\n",
    "                    'severity': 'HIGH',\n",
    "                    'suggestion': 'Implement class-aware sampling or data augmentation',\n",
    "                    'details': f'Imbalance ratio: {imbalance_ratio:.1f}'\n",
    "                })\n",
    "        \n",
    "        # 2. Image quality\n",
    "        if 'contrast' in self.quality_metrics:\n",
    "            avg_contrast = np.mean(self.quality_metrics['contrast'])\n",
    "            if avg_contrast < 30:\n",
    "                recommendations.append({\n",
    "                    'issue': 'Low contrast images',\n",
    "                    'severity': 'MEDIUM',\n",
    "                    'suggestion': 'Add contrast augmentation or preprocessing',\n",
    "                    'details': f'Average contrast: {avg_contrast:.1f}'\n",
    "                })\n",
    "        \n",
    "        # 3. BBox sizes\n",
    "        if 'train' in self.dataset_stats and 'bbox_stats' in self.dataset_stats['train']:\n",
    "            bbox_stats = self.dataset_stats['train']['bbox_stats']\n",
    "            if bbox_stats['mean_area'] < 1000:\n",
    "                recommendations.append({\n",
    "                    'issue': 'Small objects dominate',\n",
    "                    'severity': 'MEDIUM',\n",
    "                    'suggestion': 'Consider multi-scale training or focal loss',\n",
    "                    'details': f'Mean bbox area: {bbox_stats[\"mean_area\"]:.1f}'\n",
    "                })\n",
    "        \n",
    "        # 4. Data augmentation\n",
    "        recommendations.append({\n",
    "            'issue': 'Standard augmentation setup',\n",
    "            'severity': 'LOW',\n",
    "            'suggestion': 'Implement mosaic and mixup augmentations',\n",
    "            'details': 'Will improve model robustness'\n",
    "        })\n",
    "        \n",
    "        # 5. Streaming optimization\n",
    "        recommendations.append({\n",
    "            'issue': 'Real-time processing requirements',\n",
    "            'severity': 'HIGH',\n",
    "            'suggestion': 'Implement async data loading and prefetching',\n",
    "            'details': 'Critical for robotic deployment'\n",
    "        })\n",
    "        \n",
    "        # Display recommendations\n",
    "        self.display_recommendations(recommendations)\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def display_recommendations(self, recommendations):\n",
    "        \"\"\"Display recommendations in formatted table.\"\"\"\n",
    "        if not recommendations:\n",
    "            print(\"\\nNo optimization recommendations.\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nOptimization Recommendations:\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'Issue':<30} {'Severity':<10} {'Suggestion':<40} {'Details':<20}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            severity_color = {\n",
    "                'HIGH': '\\033[91m',  # Red\n",
    "                'MEDIUM': '\\033[93m', # Yellow\n",
    "                'LOW': '\\033[92m'     # Green\n",
    "            }.get(rec['severity'], '\\033[0m')\n",
    "            \n",
    "            reset_color = '\\033[0m'\n",
    "            \n",
    "            print(f\"{rec['issue'][:28]:<30} \"\n",
    "                  f\"{severity_color}{rec['severity']:<10}{reset_color} \"\n",
    "                  f\"{rec['suggestion'][:38]:<40} \"\n",
    "                  f\"{rec['details'][:18]:<20}\")\n",
    "        \n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\nTotal recommendations: {len(recommendations)}\")\n",
    "        high_count = sum(1 for r in recommendations if r['severity'] == 'HIGH')\n",
    "        medium_count = sum(1 for r in recommendations if r['severity'] == 'MEDIUM')\n",
    "        low_count = sum(1 for r in recommendations if r['severity'] == 'LOW')\n",
    "        \n",
    "        print(f\"  HIGH priority: {high_count}\")\n",
    "        print(f\"  MEDIUM priority: {medium_count}\")\n",
    "        print(f\"  LOW priority: {low_count}\")\n",
    "\n",
    "# Generate recommendations\n",
    "optimizer = DataPipelineOptimizer(config, stats, quality_metrics)\n",
    "recommendations = optimizer.generate_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e766b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Analysis Report\n",
    "\n",
    "class AnalysisReportExporter:\n",
    "    \"\"\"Export comprehensive analysis report.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, stats, quality_metrics, recommendations):\n",
    "        self.config = config\n",
    "        self.stats = stats\n",
    "        self.quality_metrics = quality_metrics\n",
    "        self.recommendations = recommendations\n",
    "        \n",
    "    def export_html_report(self, output_path='data_analysis_report.html'):\n",
    "        \"\"\"Export analysis as HTML report.\"\"\"\n",
    "        print(f\"\\nExporting analysis report to {output_path}...\")\n",
    "        \n",
    "        html_content = f\"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Humanoid Vision System - Data Analysis Report</title>\n",
    "            <style>\n",
    "                body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
    "                h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; }}\n",
    "                h2 {{ color: #34495e; margin-top: 30px; }}\n",
    "                .card {{ background: #f8f9fa; border-left: 4px solid #3498db; \n",
    "                        padding: 15px; margin: 15px 0; border-radius: 5px; }}\n",
    "                .metric {{ display: inline-block; background: white; padding: 10px; \n",
    "                         margin: 5px; border-radius: 5px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}\n",
    "                .high {{ color: #e74c3c; font-weight: bold; }}\n",
    "                .medium {{ color: #f39c12; font-weight: bold; }}\n",
    "                .low {{ color: #27ae60; font-weight: bold; }}\n",
    "                table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n",
    "                th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
    "                th {{ background-color: #3498db; color: white; }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Humanoid Vision System - Data Analysis Report</h1>\n",
    "            <p>Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "            \n",
    "            <h2>1. Dataset Statistics</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add dataset statistics\n",
    "        if self.stats:\n",
    "            for split, data in self.stats.items():\n",
    "                html_content += f\"\"\"\n",
    "                <div class=\"card\">\n",
    "                    <h3>{split.upper()} Split</h3>\n",
    "                    <div class=\"metric\">Images: {data.get('num_images', 'N/A'):,}</div>\n",
    "                    <div class=\"metric\">Annotations: {data.get('num_annotations', 'N/A'):,}</div>\n",
    "                \"\"\"\n",
    "                \n",
    "                if 'bbox_stats' in data:\n",
    "                    bbox = data['bbox_stats']\n",
    "                    html_content += f\"\"\"\n",
    "                    <div class=\"metric\">Mean BBox Area: {bbox.get('mean_area', 0):.1f}</div>\n",
    "                    <div class=\"metric\">Aspect Ratio: {bbox.get('mean_aspect_ratio', 0):.2f}</div>\n",
    "                    \"\"\"\n",
    "                \n",
    "                html_content += \"</div>\"\n",
    "        \n",
    "        # Add quality metrics\n",
    "        html_content += \"\"\"\n",
    "            <h2>2. Image Quality Metrics</h2>\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.quality_metrics:\n",
    "            html_content += \"<div class='card'>\"\n",
    "            for metric_name, values in self.quality_metrics.items():\n",
    "                if values:\n",
    "                    mean_val = np.mean(values)\n",
    "                    html_content += f\"<div class='metric'>{metric_name.title()}: {mean_val:.2f}</div>\"\n",
    "            html_content += \"</div>\"\n",
    "        \n",
    "        # Add recommendations\n",
    "        html_content += \"\"\"\n",
    "            <h2>3. Optimization Recommendations</h2>\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <th>Issue</th>\n",
    "                    <th>Severity</th>\n",
    "                    <th>Suggestion</th>\n",
    "                    <th>Details</th>\n",
    "                </tr>\n",
    "        \"\"\"\n",
    "        \n",
    "        for rec in self.recommendations:\n",
    "            severity_class = rec['severity'].lower()\n",
    "            html_content += f\"\"\"\n",
    "                <tr>\n",
    "                    <td>{rec['issue']}</td>\n",
    "                    <td class='{severity_class}'>{rec['severity']}</td>\n",
    "                    <td>{rec['suggestion']}</td>\n",
    "                    <td>{rec['details']}</td>\n",
    "                </tr>\n",
    "            \"\"\"\n",
    "        \n",
    "        html_content += \"\"\"\n",
    "            </table>\n",
    "            \n",
    "            <h2>4. Configuration Summary</h2>\n",
    "            <div class=\"card\">\n",
    "        \"\"\"\n",
    "        \n",
    "        for key, value in self.config.items():\n",
    "            html_content += f\"<div class='metric'>{key}: {value}</div>\"\n",
    "        \n",
    "        html_content += \"\"\"\n",
    "            </div>\n",
    "            \n",
    "            <h2>5. Action Items</h2>\n",
    "            <div class=\"card\">\n",
    "                <ol>\n",
    "                    <li>Address HIGH priority recommendations immediately</li>\n",
    "                    <li>Implement data augmentation pipeline</li>\n",
    "                    <li>Set up streaming data validation</li>\n",
    "                    <li>Monitor data quality during training</li>\n",
    "                    <li>Regularly update this analysis</li>\n",
    "                </ol>\n",
    "            </div>\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "        \n",
    "        # Write HTML file\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(html_content)\n",
    "        \n",
    "        print(f\"Report exported successfully to {output_path}\")\n",
    "        \n",
    "        # Also export as JSON\n",
    "        self.export_json_report('data_analysis_report.json')\n",
    "    \n",
    "    def export_json_report(self, output_path='data_analysis_report.json'):\n",
    "        \"\"\"Export analysis as JSON report.\"\"\"\n",
    "        report_data = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'config': self.config,\n",
    "            'dataset_stats': self.stats,\n",
    "            'quality_metrics': {k: {\n",
    "                'mean': float(np.mean(v)) if v else 0,\n",
    "                'std': float(np.std(v)) if v else 0,\n",
    "                'count': len(v)\n",
    "            } for k, v in self.quality_metrics.items()},\n",
    "            'recommendations': self.recommendations,\n",
    "            'summary': {\n",
    "                'total_recommendations': len(self.recommendations),\n",
    "                'high_priority': sum(1 for r in self.recommendations if r['severity'] == 'HIGH'),\n",
    "                'medium_priority': sum(1 for r in self.recommendations if r['severity'] == 'MEDIUM'),\n",
    "                'low_priority': sum(1 for r in self.recommendations if r['severity'] == 'LOW')\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        import json\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(report_data, f, indent=2)\n",
    "        \n",
    "        print(f\"JSON report exported to {output_path}\")\n",
    "\n",
    "# Export reports\n",
    "report_exporter = AnalysisReportExporter(config, stats, quality_metrics, recommendations)\n",
    "report_exporter.export_html_report('../reports/data_analysis_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c095213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA PIPELINE ANALYSIS - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n COMPLETED:\")\n",
    "print(\"  1. Dataset statistics loaded and analyzed\")\n",
    "print(\"  2. Data loading pipeline tested\")\n",
    "print(\"  3. Augmentation pipeline visualized\")\n",
    "print(\"  4. Streaming simulation analyzed\")\n",
    "print(\"  5. Data quality checks performed\")\n",
    "print(\"  6. Memory usage analyzed\")\n",
    "print(\"  7. Optimization recommendations generated\")\n",
    "print(\"  8. Analysis reports exported\")\n",
    "\n",
    "print(\"\\n KEY FINDINGS:\")\n",
    "if 'train' in stats:\n",
    "    print(f\"   Dataset: {stats['train']['num_images']:,} training images\")\n",
    "    print(f\"   Objects: {stats['train']['num_annotations']:,} annotations\")\n",
    "    \n",
    "if quality_metrics and 'contrast' in quality_metrics:\n",
    "    avg_contrast = np.mean(quality_metrics['contrast'])\n",
    "    print(f\"   Image quality: Average contrast = {avg_contrast:.1f}\")\n",
    "\n",
    "print(f\"\\n NEXT STEPS:\")\n",
    "print(\"  1. Address HIGH priority recommendations\")\n",
    "print(\"  2. Implement suggested augmentations\")\n",
    "print(\"  3. Set up data versioning pipeline\")\n",
    "print(\"  4. Create data validation tests\")\n",
    "print(\"  5. Proceed to model analysis (02_model_analysis.ipynb)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
